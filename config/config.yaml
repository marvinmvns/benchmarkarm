# Raspberry Pi Voice Processor - Configuração
# =============================================

# Modo de operação: local, api, hybrid
mode: "hybrid"

# Configuração de Áudio (ReSpeaker)
audio:
  # Dispositivo de áudio (deixe vazio para auto-detectar)
  device: ""

  # Taxa de amostragem (16000 é ideal para Whisper)
  sample_rate: 16000

  # Canais (1 = mono, recomendado)
  channels: 1

  # Tamanho do chunk em frames
  chunk_size: 1024

  # Duração máxima de gravação em segundos
  max_duration: 30

  # Silêncio para parar gravação (segundos)
  silence_duration: 2.0

  # VAD (Voice Activity Detection)
  vad:
    enabled: true
    # Agressividade: 0-3 (3 = mais agressivo, filtra mais ruído)
    aggressiveness: 2
    # Duração mínima de fala para considerar válido (segundos)
    min_speech_duration: 0.5

# Configuração do Whisper (Transcrição)
whisper:
  # Modelo: tiny, base, small, medium, large
  # Para Pi Zero 2W: use "tiny" ou "base"
  # Para Pi 4+: pode usar "small"
  model: "tiny"

  # Idioma: pt, en, es, etc. (vazio = auto-detect)
  language: "pt"

  # Usar whisper.cpp (mais rápido) ou whisper Python
  use_cpp: true

  # Número de threads (0 = auto)
  threads: 4

  # Quantização do modelo (para whisper.cpp)
  # Opções: f16, q8_0, q5_0, q4_0
  quantization: "q5_0"

  # Beam search size (menor = mais rápido)
  beam_size: 1

  # Suprimir tokens de silêncio
  suppress_blank: true

# Configuração do LLM (Resumo/Processamento)
llm:
  # Provider: local, openai, anthropic, ollama
  provider: "local"

  # Configuração Local (llama.cpp)
  local:
    # Modelo: tinyllama, phi2, gemma-2b
    model: "tinyllama"

    # Caminho do modelo (se custom)
    model_path: ""

    # Contexto máximo
    context_size: 512

    # Threads
    threads: 4

    # Tokens máximos na resposta
    max_tokens: 150

    # Temperatura (0 = determinístico)
    temperature: 0.3

    # Quantização
    quantization: "q4_0"

  # Configuração OpenAI
  openai:
    api_key: "${OPENAI_API_KEY}"
    model: "gpt-4o-mini"
    max_tokens: 200
    temperature: 0.3

  # Configuração Anthropic
  anthropic:
    api_key: "${ANTHROPIC_API_KEY}"
    model: "claude-3-haiku-20240307"
    max_tokens: 200
    temperature: 0.3

  # Configuração Ollama (servidor local)
  ollama:
    host: "http://localhost:11434"
    model: "tinyllama"
    max_tokens: 200

# Prompts para o LLM
prompts:
  # Prompt para resumo
  summarize: |
    Resuma o seguinte texto de forma concisa, mantendo os pontos principais:

    {text}

    Resumo:

  # Prompt para extração de ações
  extract_actions: |
    Extraia as ações e tarefas mencionadas no texto:

    {text}

    Ações:

  # Prompt customizado
  custom: ""

# Sistema
system:
  # Habilitar cache de transcrições
  cache_enabled: true

  # Diretório de cache
  cache_dir: "~/.cache/voice-processor"

  # Tempo de vida do cache (segundos)
  cache_ttl: 3600

  # Logging
  log_level: "INFO"
  log_file: ""

  # Modo de baixa memória (para Pi Zero 2W)
  low_memory_mode: true

  # Tempo máximo de processamento (segundos)
  timeout: 60

# Hardware
hardware:
  # Tipo de ReSpeaker: 2mic, 4mic, 6mic
  respeaker_type: "2mic"

  # Habilitar LEDs do ReSpeaker
  led_enabled: true

  # GPIO do botão (se disponível)
  button_gpio: 17

# =============================================================================
# Fila Offline (para quando não há conexão com internet)
# =============================================================================
offline_queue:
  # Habilitar sistema de filas offline
  enabled: true

  # Caminho do banco de dados SQLite
  db_path: "~/.cache/voice-processor/queue.db"

  # Tamanho máximo da fila
  max_queue_size: 1000

  # Delay base para retry (segundos)
  retry_delay_base: 30.0

  # Máximo de retries por tarefa
  max_retries: 3

  # Intervalo de verificação de conectividade (segundos)
  connectivity_check_interval: 60.0

  # Processar fila automaticamente quando voltar online
  auto_process_on_reconnect: true

  # Fallback para LLM local quando offline
  use_local_fallback: true

# =============================================================================
# Gerenciamento de Energia (Feature Toggle)
# =============================================================================
power_management:
  # *** FEATURE TOGGLE - Habilitar gerenciamento de energia ***
  enabled: false

  # Modo padrão: performance, balanced, power_save, ultra_power_save
  default_mode: "balanced"

  # Modo automático (ajusta baseado em atividade e temperatura)
  auto_adjust: true

  # Tempo de inatividade para entrar em modo idle (segundos)
  idle_timeout: 60.0

  # Modo quando idle
  idle_mode: "power_save"

  # Limites de temperatura para throttling automático
  thermal:
    # Temperatura para reduzir performance (Celsius)
    threshold_high: 70.0
    # Temperatura crítica (Celsius)
    threshold_critical: 80.0

  # Configurações por modo
  profiles:
    performance:
      cpu_governor: "performance"
      cpu_freq_max: null  # Sem limite
      disable_hdmi: false
      disable_bluetooth: false
      led_brightness: 255

    balanced:
      cpu_governor: "ondemand"
      cpu_freq_max: null
      disable_hdmi: false
      disable_bluetooth: false
      led_brightness: 128

    power_save:
      cpu_governor: "powersave"
      cpu_freq_max: 600  # MHz
      disable_hdmi: true
      disable_bluetooth: true
      led_brightness: 32

    ultra_power_save:
      cpu_governor: "powersave"
      cpu_freq_max: 400  # MHz
      disable_hdmi: true
      disable_bluetooth: true
      led_brightness: 0

# =============================================================================
# Interface Web (Feature Toggle)
# =============================================================================
web_interface:
  # *** FEATURE TOGGLE - Habilitar interface web ***
  enabled: false

  # Host e porta do servidor
  host: "0.0.0.0"
  port: 8080

  # Modo debug (não usar em produção)
  debug: false

  # Autenticação básica (opcional)
  auth:
    enabled: false
    username: "admin"
    # Senha hash - gere com: python -c "import hashlib; print(hashlib.sha256(b'sua_senha').hexdigest())"
    password_hash: ""

  # CORS (para acesso de outros dispositivos)
  cors_enabled: true

  # Rate limiting (requisições por minuto)
  rate_limit: 60
